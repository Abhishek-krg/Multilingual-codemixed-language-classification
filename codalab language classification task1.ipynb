{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Offensive Language Classification</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import essential modules\n",
    "import pandas as pd\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll begin by loading and cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create df object to store dataset\n",
    "df_train=pd.read_csv('OffensiveLanguage/Task1/tamil_offensive_train.tsv', sep='\\t')\n",
    "df_test=pd.read_csv('OffensiveLanguage/Task1/tam_offesive_withoutlabels_test.tsv.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.astype({'id':'string','text':'string','category':'string'}) #cast values to useable format\n",
    "df_test=df_test.astype({'id':'string','text':'string','category':'string'}) #cast values to useable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tam1</td>\n",
       "      <td>родро┐ро░рпБрооро▓рпИ роиро╛ропроХрпНроХро░рпН рокрпЗро░ро╡рпИ роЪро╛ро░рпНрокро╛роХ рокроЯроорпН ро╡рпЖро▒рпНро▒ро┐ рокрпЖро▒...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tam2</td>\n",
       "      <td>роЗроирпНрод роЯрпНро░рпЖропрпНро▓ро░рпН роХрпВроЯ рокро╛ро░рпНроХрпНроХро┐ро▒ рооро╛родро┐ро░ро┐ роЗро▓рпНро▓рпИ.. роЗрод...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tam3</td>\n",
       "      <td>роорпИроЪрпВро░рпБ роЪрпЖроЯрпНроЯро┐ропро╛ро░рпН роЪроорпВроХродрпНродро┐ройрпН роЪро╛ро░рпНрокро╛роХ роЗрокрпНрокроЯроорпН ро╡...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tam4</td>\n",
       "      <td>роорпКродрпНрод роЪро╛родро┐ропрпБроорпН роТро░рпБ роЪро╛родро┐роХрпНроХрпБ роОродро┐ро░ро╛ роиро┐роХрпНроХрпБродрпБ.......</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tam5</td>\n",
       "      <td>only for ро╡ро┐роЬропрпН роЪрпЗродрпБрокродро┐ and STR</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text category\n",
       "0  tam1  родро┐ро░рпБрооро▓рпИ роиро╛ропроХрпНроХро░рпН рокрпЗро░ро╡рпИ роЪро╛ро░рпНрокро╛роХ рокроЯроорпН ро╡рпЖро▒рпНро▒ро┐ рокрпЖро▒...      NOT\n",
       "1  tam2  роЗроирпНрод роЯрпНро░рпЖропрпНро▓ро░рпН роХрпВроЯ рокро╛ро░рпНроХрпНроХро┐ро▒ рооро╛родро┐ро░ро┐ роЗро▓рпНро▓рпИ.. роЗрод...      OFF\n",
       "2  tam3  роорпИроЪрпВро░рпБ роЪрпЖроЯрпНроЯро┐ропро╛ро░рпН роЪроорпВроХродрпНродро┐ройрпН роЪро╛ро░рпНрокро╛роХ роЗрокрпНрокроЯроорпН ро╡...      NOT\n",
       "3  tam4  роорпКродрпНрод роЪро╛родро┐ропрпБроорпН роТро░рпБ роЪро╛родро┐роХрпНроХрпБ роОродро┐ро░ро╛ роиро┐роХрпНроХрпБродрпБ.......      OFF\n",
       "4  tam5                     only for ро╡ро┐роЬропрпН роЪрпЗродрпБрокродро┐ and STR      NOT"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional remove ... from end of comments\n",
    "for i in df.index:\n",
    "    df.loc[i,'text']=df.loc[i,'text'].strip('.')\n",
    "df.head() # notice the text in head() appears to have ... but thats just pandas max-display length limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tam1</td>\n",
       "      <td>родро┐ро░рпБрооро▓рпИ роиро╛ропроХрпНроХро░рпН рокрпЗро░ро╡рпИ роЪро╛ро░рпНрокро╛роХ рокроЯроорпН ро╡рпЖро▒рпНро▒ро┐ рокрпЖро▒...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tam2</td>\n",
       "      <td>роЗроирпНрод роЯрпНро░рпЖропрпНро▓ро░рпН роХрпВроЯ рокро╛ро░рпНроХрпНроХро┐ро▒ рооро╛родро┐ро░ро┐ роЗро▓рпНро▓рпИ.. роЗрод...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tam3</td>\n",
       "      <td>роорпИроЪрпВро░рпБ роЪрпЖроЯрпНроЯро┐ропро╛ро░рпН роЪроорпВроХродрпНродро┐ройрпН роЪро╛ро░рпНрокро╛роХ роЗрокрпНрокроЯроорпН ро╡...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tam4</td>\n",
       "      <td>роорпКродрпНрод роЪро╛родро┐ропрпБроорпН роТро░рпБ роЪро╛родро┐роХрпНроХрпБ роОродро┐ро░ро╛ роиро┐роХрпНроХрпБродрпБ.......</td>\n",
       "      <td>OFF</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tam5</td>\n",
       "      <td>only for ро╡ро┐роЬропрпН роЪрпЗродрпБрокродро┐ and STR</td>\n",
       "      <td>NOT</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text category label\n",
       "0  tam1  родро┐ро░рпБрооро▓рпИ роиро╛ропроХрпНроХро░рпН рокрпЗро░ро╡рпИ роЪро╛ро░рпНрокро╛роХ рокроЯроорпН ро╡рпЖро▒рпНро▒ро┐ рокрпЖро▒...      NOT     _\n",
       "1  tam2  роЗроирпНрод роЯрпНро░рпЖропрпНро▓ро░рпН роХрпВроЯ рокро╛ро░рпНроХрпНроХро┐ро▒ рооро╛родро┐ро░ро┐ роЗро▓рпНро▓рпИ.. роЗрод...      OFF     _\n",
       "2  tam3  роорпИроЪрпВро░рпБ роЪрпЖроЯрпНроЯро┐ропро╛ро░рпН роЪроорпВроХродрпНродро┐ройрпН роЪро╛ро░рпНрокро╛роХ роЗрокрпНрокроЯроорпН ро╡...      NOT     _\n",
       "3  tam4  роорпКродрпНрод роЪро╛родро┐ропрпБроорпН роТро░рпБ роЪро╛родро┐роХрпНроХрпБ роОродро┐ро░ро╛ роиро┐роХрпНроХрпБродрпБ.......      OFF     _\n",
       "4  tam5                     only for ро╡ро┐роЬропрпН роЪрпЗродрпБрокродро┐ and STR      NOT     _"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add label coloumn in train df to convert catgories to machine usable labels\n",
    "df_train.insert(3,'label','_')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert category to machine usable labels\n",
    "for i in df_train.index:\n",
    "    if df_train.loc[i,'category']=='NOT':\n",
    "        df_train.loc[i,'label']=0\n",
    "    else:\n",
    "        df_train.loc[i,'label']=1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate frequency dictionary and return max sentence length\n",
    "def gen_word_encodings(df,word_freq):\n",
    "    num_recs=df.index.stop\n",
    "    max_len=0\n",
    "    for i in df.index:\n",
    "        words=df['text'][i].strip().split()\n",
    "        if(len(words)>max_len):\n",
    "            max_len=len(words)\n",
    "        for word in words:\n",
    "            word_freq[word]+=1\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Encodings\n",
    "word_freq=collections.Counter()\n",
    "max_len=gen_word_encodings(df_train,word_freq) #these 2steps are important to properly load the data \n",
    "#word to index maps as{\"word1\":idx1,\"word2\":idx2...}\n",
    "word2idx={x[0]:i+2 for i,x in enumerate(word_freq.most_common(len(word_freq)))}\n",
    "word2idx[\"PAD\"]=0\n",
    "word2idx[\"UNK\"]=1\n",
    "#idx to word mapping\n",
    "idx2word={v:k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24754"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not needed for dataset but we need this for stripping off the unwanted chars and emojis in dataset\n",
    "def gen_char_encodings(word_freq,char_freq):\n",
    "    max_word_len=0\n",
    "    for keys in word_freq:\n",
    "        if(len(keys)>max_word_len):\n",
    "            max_word_len=len(keys)\n",
    "        chars=list(keys)\n",
    "        for char in chars:\n",
    "            char_freq[char]+=1\n",
    "    return max_word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_freq=collections.Counter()\n",
    "max_word_len=gen_char_encodings(word_freq,char_freq)\n",
    "char2idx={x[0]:i+2 for i,x in enumerate(char_freq.most_common(len(char_freq)))}\n",
    "char2idx[\"PAD\"]=0\n",
    "char2idx[\"UNK\"]=1\n",
    "#idx to char mapping\n",
    "idx2char={v:k for k,v in char2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_word_len # input length to embedding vector\n",
    "char2idx #('ЁЯдг', 'ЁЯдФ', 'ЁЯжБ', 'ЁЯдж', 'ЁЯдЭ', 'ЁЯдЧ', 'ЁЯдй', 'ЁЯдк', 'ЁЯен', 'ЁЯдл', 'ЁЯдШ', 'ЁЯдм', 'ЁЯдЩ', 'ЁЯе│', 'ЁЯди', 'ЁЯзР', 'ЁЯе░', 'ЁЯеЗ', 'ЁЯе╢', 'ЁЯеК', 'ЁЯдЫ', 'ЁЯдЮ', 'ЁЯдХ', 'ЁЯдн', 'ЁЯдЯ', 'ЁЯдР', 'ЁЯд║', 'ЁЯзб', 'ЁЯж╕', 'тПо', 'тП╕', 'тПн', 'ЁЯдз', '\\U0001f7e0','ЁЯжН', 'ЁЯзЯ', 'ЁЯеБ', 'ЁЯда', 'ЁЯжМ', 'ЁЯжД', 'ЁЯдУ', 'ЁЯзи', 'ЁЯдо', 'тП░', 'ЁЯжЕ', '\\u2066', '\\u2069', '\\u200b', '\\u200d', '\\u200c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emojis and unwanted characters from the dataframe\n",
    "for i in df_train.index:\n",
    "    df_train.loc[i,'text']=df_train.loc[i,'text'].translate({ord(j): None for j in ('ЁЯжВ','ЁЯдг', 'ЁЯдФ', 'ЁЯжБ', 'ЁЯдж', 'ЁЯдЭ', 'ЁЯдЧ', 'ЁЯдй', 'ЁЯдк', 'ЁЯен', 'ЁЯдл', 'ЁЯдШ', 'ЁЯдм', 'ЁЯдЩ', 'ЁЯе│', 'ЁЯди', 'ЁЯзР', 'ЁЯе░', 'ЁЯеЗ', 'ЁЯе╢', 'ЁЯеК', 'ЁЯдЫ', 'ЁЯдЮ', 'ЁЯдХ', 'ЁЯдн', 'ЁЯдЯ', 'ЁЯдР', 'ЁЯд║', 'ЁЯзб', 'ЁЯж╕', 'тПо', 'тП╕', 'тПн', 'ЁЯдз', '\\U0001f7e0','ЁЯжН', 'ЁЯзЯ', 'ЁЯеБ', 'ЁЯда', 'ЁЯжМ', 'ЁЯжД', 'ЁЯдУ', 'ЁЯзи', 'ЁЯдо', 'тП░', 'ЁЯжЕ', '\\u2066', '\\u2069', '\\u200b', '\\u200d', '\\u200c','\\U000fe4eb')})\n",
    "\n",
    "# remove emojis and unwanted characters from the dataframe\n",
    "for i in df_test.index:\n",
    "    df_test.loc[i,'text']=df_test.loc[i,'text'].translate({ord(j): None for j in ('ЁЯжВ','ЁЯдг', 'ЁЯдФ', 'ЁЯжБ', 'ЁЯдж', 'ЁЯдЭ', 'ЁЯдЧ', 'ЁЯдй', 'ЁЯдк', 'ЁЯен', 'ЁЯдл', 'ЁЯдШ', 'ЁЯдм', 'ЁЯдЩ', 'ЁЯе│', 'ЁЯди', 'ЁЯзР', 'ЁЯе░', 'ЁЯеЗ', 'ЁЯе╢', 'ЁЯеК', 'ЁЯдЫ', 'ЁЯдЮ', 'ЁЯдХ', 'ЁЯдн', 'ЁЯдЯ', 'ЁЯдР', 'ЁЯд║', 'ЁЯзб', 'ЁЯж╕', 'тПо', 'тП╕', 'тПн', 'ЁЯдз', '\\U0001f7e0','ЁЯжН', 'ЁЯзЯ', 'ЁЯеБ', 'ЁЯда', 'ЁЯжМ', 'ЁЯжД', 'ЁЯдУ', 'ЁЯзи', 'ЁЯдо', 'тП░', 'ЁЯжЕ', '\\u2066', '\\u2069', '\\u200b', '\\u200d', '\\u200c','\\U000fe4eb')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can now create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate dataset\n",
    "def create_dataset(df,x,y):\n",
    "    for i in df.index:\n",
    "        words=df['text'][i].strip().split()\n",
    "        seqs=[]\n",
    "        for word in words:\n",
    "            if word in word2idx:\n",
    "                seqs.append(word2idx[word])\n",
    "            else:\n",
    "                seqs.append(word2idx[\"UNK\"])\n",
    "        x[i]=seqs\n",
    "        cat=df['category'][i]\n",
    "        if(cat=='OFF'):\n",
    "            y[i]=1\n",
    "        else:\n",
    "            y[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_recs=df_train.index.stop\n",
    "x=np.empty((num_recs,),dtype=list) # x holds sentence vectors \n",
    "y=np.zeros((num_recs,),dtype=\"uint8\") # y holds category 1 for Offensive 0 for Not-Offensive\n",
    "create_dataset(df_train,x,y)\n",
    "x=tf.keras.preprocessing.sequence.pad_sequences(x,maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenxt=int(x.shape[0]*0.7)\n",
    "xt=x[:lenxt] # x-train split with 70% data\n",
    "yt=y[:lenxt] # y-train split with 70% data\n",
    "xtt=x[lenxt:] # x-evaluation split with 30% data\n",
    "ytt=y[lenxt:] # y-evaluation split with 30% data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1 LSTM units 64 perf ~80%\n",
    "vocab_size=len(word2idx)\n",
    "model=tf.keras.models.Sequential([tf.keras.layers.Embedding(vocab_size,128,mask_zero=True,input_length=50),\n",
    "                                  tf.keras.layers.LSTM(64,dropout=0.25,recurrent_dropout=0.1,return_sequences=True,unroll=True)\n",
    "                                  tf.keras.layers.Dense(1,activation=\"sigmoid\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2 bidirectional LSTM with 32 units perf ~81%\n",
    "# Test 3 bidirectional LSTM with 64 units perf ~81% increasing number of units does not effect perf\n",
    "vocab_size=len(word2idx)\n",
    "model=tf.keras.models.Sequential([tf.keras.layers.Embedding(vocab_size,128,input_length=50),\n",
    "                                tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,dropout=0.2,recurrent_dropout=0.2),merge_mode='concat'),\n",
    "                                tf.keras.layers.Dense(1,activation=\"sigmoid\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4 seperate forward backward LSTM layers in bidirectional with 32 units each perf ~82.5%\n",
    "# Test 5 seperate forward backward LSTM layers in bidirectional with 16 units each perf ~80%\n",
    "# Test 6 seperate forward backward LSTM layers in bidirectional with 32 units each increasing dropout to 30% perf ~82%\n",
    "# Test 7 seperate forward backward LSTM layers in bidirectional with 32 units each decreasing dropout to 25% and 10% perf ~82.7%\n",
    "\n",
    "vocab_size=len(word2idx)\n",
    "forward_layer = tf.keras.layers.LSTM(32,dropout=0.25,recurrent_dropout=0.1,return_sequences=False)\n",
    "backward_layer = tf.keras.layers.LSTM(32,activation='relu',dropout=0.25,recurrent_dropout=0.1,return_sequences=False,go_backwards=True)\n",
    "model=tf.keras.models.Sequential([tf.keras.layers.Embedding(vocab_size,128,input_length=50),\n",
    "                                tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer,merge_mode='concat'),\n",
    "                                tf.keras.layers.Dense(1,activation=\"sigmoid\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "184/184 [==============================] - 30s 164ms/step - loss: 0.4436 - accuracy: 0.8054\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.1986 - accuracy: 0.9277\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 29s 158ms/step - loss: 0.0493 - accuracy: 0.9862\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 29s 155ms/step - loss: 0.0205 - accuracy: 0.9954\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0118 - accuracy: 0.9974\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 30s 161ms/step - loss: 0.0106 - accuracy: 0.9971\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 30s 160ms/step - loss: 0.0072 - accuracy: 0.9980\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 30s 162ms/step - loss: 0.0035 - accuracy: 0.9983\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 30s 160ms/step - loss: 0.0026 - accuracy: 0.9985\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0025 - accuracy: 0.9985\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0022 - accuracy: 0.9990\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.0020 - accuracy: 0.9990\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 30s 161ms/step - loss: 0.0018 - accuracy: 0.9986\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 30s 162ms/step - loss: 0.0038 - accuracy: 0.9981\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.0037 - accuracy: 0.9976\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 30s 163ms/step - loss: 0.0034 - accuracy: 0.9976\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0020 - accuracy: 0.9985\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 30s 162ms/step - loss: 0.0018 - accuracy: 0.9988\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.0017 - accuracy: 0.9986\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 30s 163ms/step - loss: 0.0017 - accuracy: 0.9986\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0017 - accuracy: 0.9990\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 29s 158ms/step - loss: 0.0017 - accuracy: 0.9988\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 29s 157ms/step - loss: 0.0017 - accuracy: 0.9986\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 30s 163ms/step - loss: 0.0017 - accuracy: 0.9985\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 30s 162ms/step - loss: 0.0016 - accuracy: 0.9986\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0016 - accuracy: 0.9986\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.0016 - accuracy: 0.9988\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 30s 163ms/step - loss: 0.0016 - accuracy: 0.9986\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 29s 158ms/step - loss: 0.0016 - accuracy: 0.9986\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 30s 162ms/step - loss: 0.0016 - accuracy: 0.9985\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 29s 157ms/step - loss: 0.0016 - accuracy: 0.9990\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.0016 - accuracy: 0.9985\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 29s 158ms/step - loss: 0.0016 - accuracy: 0.9986\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 30s 160ms/step - loss: 0.0016 - accuracy: 0.9985\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 29s 158ms/step - loss: 0.0016 - accuracy: 0.9988\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.0016 - accuracy: 0.9986\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 29s 156ms/step - loss: 0.0016 - accuracy: 0.9990\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 29s 157ms/step - loss: 0.0016 - accuracy: 0.9990\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0016 - accuracy: 0.9988\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 30s 163ms/step - loss: 0.0016 - accuracy: 0.9985\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.0016 - accuracy: 0.9988\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 29s 157ms/step - loss: 0.0016 - accuracy: 0.9985\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 29s 158ms/step - loss: 0.0016 - accuracy: 0.9990\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 30s 161ms/step - loss: 0.0016 - accuracy: 0.9988\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.0016 - accuracy: 0.9991\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0016 - accuracy: 0.9986\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 29s 158ms/step - loss: 0.0016 - accuracy: 0.9986\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.0016 - accuracy: 0.9983\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 30s 161ms/step - loss: 0.0016 - accuracy: 0.9990\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "hist=model.fit(x,y,batch_size=32,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to hdf5 file\n",
    "model.save('task1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.models.load_model('task1.h5')\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_test.index:\n",
    "    words=df_test.loc[i,'text'].strip().split()\n",
    "    seqs=[]\n",
    "    for word in words:\n",
    "        if word in word2idx:\n",
    "            seqs.append(word2idx[word])\n",
    "        else:\n",
    "            seqs.append(word2idx[\"UNK\"])\n",
    "    seqs=[seqs]\n",
    "    seqs=tf.keras.preprocessing.sequence.pad_sequences(seqs,maxlen=50)\n",
    "    if(model(seqs)[0][0]>0.40):\n",
    "        preds=\"OFF\"\n",
    "    else:\n",
    "        preds=\"NOT\"\n",
    "    df_test.loc[i,'category']=preds\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test predictions to file\n",
    "df_test.to_csv('OffensiveLanguage/Task1/task1_submission.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot model AUC curve\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(211)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(hist.history[\"accuracy\"],color='b',label='Train')\n",
    "plt.plot(hist.history[\"val_accuracy\"],color='g',label='Validation')\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Loss')\n",
    "plt.plot(hist.history[\"loss\"],color='#FFA500',label='Train')\n",
    "plt.plot(hist.history[\"val_loss\"],color='g',label='Validation')\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
